{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## IMPORTS\n",
    "import random, os, pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "##########\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical#, normalize\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "##########\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "import pandas\n",
    "import cv2\n",
    "from PIL import Image\n",
    "#from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DATASET IMPORT AND PREPROCESSING\n",
    "classes = 43\n",
    "data = []\n",
    "labels = []\n",
    "cur_path = os.getcwd()\n",
    "path = os.path.join(cur_path,'archive/train')\n",
    "\n",
    "for i in range(classes):\n",
    "    new_path = os.path.join(path,str(i))\n",
    "    images = os.listdir(new_path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(new_path +'/'+ a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "# converting into numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "#np.save('./training/data',data)\n",
    "#np.save('./training/target',labels)\n",
    "#data=np.load('./training/data.npy')\n",
    "#labels=np.load('./training/target.npy')\n",
    "\n",
    "\n",
    "#print(data[0])\n",
    "#print(data.shape)\n",
    "#print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATING THE MODEL\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, random_state = 42)\n",
    "#print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "########## BASELINE MODEL\n",
    "base_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(30, 30, 1)),\n",
    "    tf.keras.layers.Dense(43)\n",
    "])\n",
    "\n",
    "base_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.2008 - accuracy: 0.9498\n",
      "Epoch 2/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1945 - accuracy: 0.9517\n",
      "Epoch 3/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1881 - accuracy: 0.9525\n",
      "Epoch 4/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1855 - accuracy: 0.9537\n",
      "Epoch 5/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1741 - accuracy: 0.9568\n",
      "Epoch 6/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1759 - accuracy: 0.9564\n",
      "Epoch 7/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1859 - accuracy: 0.9546\n",
      "Epoch 8/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1641 - accuracy: 0.9608\n",
      "Epoch 9/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1599 - accuracy: 0.9584\n",
      "Epoch 10/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1671 - accuracy: 0.9577\n",
      "Epoch 11/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1564 - accuracy: 0.9609\n",
      "Epoch 12/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1611 - accuracy: 0.9596\n",
      "Epoch 13/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1602 - accuracy: 0.9598\n",
      "Epoch 14/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1488 - accuracy: 0.9624\n",
      "Epoch 15/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1437 - accuracy: 0.9631\n",
      "Epoch 16/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1447 - accuracy: 0.9616\n",
      "Epoch 17/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1453 - accuracy: 0.9635\n",
      "Epoch 18/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1368 - accuracy: 0.9652\n",
      "Epoch 19/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1549 - accuracy: 0.9608\n",
      "Epoch 20/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1293 - accuracy: 0.9677\n",
      "Epoch 21/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1381 - accuracy: 0.9649\n",
      "Epoch 22/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1246 - accuracy: 0.9669\n",
      "Epoch 23/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1329 - accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1426 - accuracy: 0.9637\n",
      "Epoch 25/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1208 - accuracy: 0.9684\n",
      "Epoch 26/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1265 - accuracy: 0.9657\n",
      "Epoch 27/30\n",
      "919/919 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9647\n",
      "Epoch 28/30\n",
      "919/919 [==============================] - 2s 3ms/step - loss: 0.1166 - accuracy: 0.9717\n",
      "Epoch 29/30\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.1248 - accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "919/919 [==============================] - 3s 3ms/step - loss: 0.1125 - accuracy: 0.9711\n",
      "307/307 - 0s - loss: 0.2384 - accuracy: 0.9524\n",
      "Test accuracy: 0.952361524105072\n"
     ]
    }
   ],
   "source": [
    "########## MODEL FITTING > TRAINING > TESTING\n",
    "base_model.fit(X_train, y_train, epochs=30)\n",
    "\n",
    "test_loss, test_acc = base_model.evaluate(X_test,  y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MODEL VISUALIZATION\n",
    "ann_viz(base_model, title=\"My first neural network\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondae4692c67761a4c9c9c06d1f7c3909cd9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
